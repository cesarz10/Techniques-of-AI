{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nVgXdrmlY-ix"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(138)\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0Ls-YB3LwF6"
   },
   "source": [
    "# Part 1: Assembling a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZbux4GlOzYH"
   },
   "source": [
    "commands from *pandas* that might be useful for any ML problem ( particularly your assignment). We will approach this by assembling a dataframe from 3 different data sources. These three files are *df_vlinder.csv*, *df_meta.csv* and *df_synop.csv*. Your final result must be the same as the *df_merged.csv* file. You can use this file as a reference point for your answer for part 1.\n",
    "\n",
    "Here you will find a list of commands that you might find useful for this notebook:\n",
    "\n",
    "*   pandas.to_datetime\n",
    "*   pandas.DataFrame.pop\n",
    "*   pandas.DataFrame.reset_index\n",
    "*   pandas.DataFrame.set_index\n",
    "*   pandas.DataFrame.resample\n",
    "*   pandas.DataFrame.merge \n",
    "*   pandas.to_numeric \n",
    "*   pandas.DataFrame.rename \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mRfk40EGYH3c"
   },
   "outputs": [],
   "source": [
    "df_vlinder = pd.read_csv('df_vlinder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1dBkNaqCsbsf"
   },
   "outputs": [],
   "source": [
    "df_vlinder.to_csv('df_vlinder.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I3FMgVqsDzDO"
   },
   "outputs": [],
   "source": [
    "df_vlinder=df_vlinder.rename(columns={\"Temperatuur\":\"TEMP\",\"Neerslagintensiteit\": \"PRECIP_QUANTITY\", \"Luchtdruk\":\"PRESSURE\", \"Windrichting\": \"WIND_DIRECTION\",\n",
    "                                    \"Windsnelheid\": \"WIND_SPEED\", \"Vochtigheid\":\"HUMIDITY_RELATIVE\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "G3dPwvmUp182",
    "outputId": "3a985449-0d03-423e-82a1-1e4d491c1b2d"
   },
   "outputs": [],
   "source": [
    "df_vlinder.TEMP.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI5C03YnYjLx"
   },
   "source": [
    "This figure shows the temperature at station vlinder 16 for June and July. You can find this station on the Vlinder dashboard (https://vlinder.ugent.be/dashboard/?stations=vlinder16) Do we want to keep all this data? If not, which month should we perhaps throw out?\n",
    "\n",
    "Further, we have the date (Datum), and we have the time (Tijd (UTC)) in hours, minutes, and seconds. See if you can combine these into a DateTime column. This will be useful for later on. All the variables left in Dutch will not be used further, so you should delete these columns. As we'll see, when loading in the synop data, there is a mismatch between the frequency at which the measurements are made. How can we solve this? Which data set would we modify for this (vlinder or synop)? Keep in mind that certain variables behave differently when considering different measuring frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLoxq_rr1Nna"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkDFFG-aZfsB"
   },
   "source": [
    "In this following part we load in the metadata. This dataframe contains information of the surrounding area of the station. We want from to add information from this file to be added to our main merged file. Specifically, the altitude (height), longitude (lon), lattitude (lat) and the three land cover fractions (water, green & impervious). These three fractions we specifically want for a buffer size of 150 m (tip look at the values of radius).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l7IVBDCVSzg3"
   },
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('df_meta.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "gkHWEbigS73V",
    "outputId": "2eb98b16-c5f4-4249-c64d-1b8dbafc85e2"
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWext1SC1UO5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsCnAb7QnS45"
   },
   "source": [
    "In this part, we will load in the data from 2 synoptic stations: one in Antwerpen (Deurne) and one in Stabroek. These two stations can be found on the following map (https://www.google.com/maps/d/u/0/viewer?mid=1tgyYVHdsD4xL_FixPol8NwBc8GY&ll=50.57784013934338%2C4.264776500000016&z=6) These two stations are the closest to vlinder 16. We will use the temperature, wind speed, and radiation information of one of these two stations and append this to our big dataframe. Which one would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X3PRIHsrk98Q"
   },
   "outputs": [],
   "source": [
    "df_synop=pd.read_csv('df_synop.csv')\n",
    "df_synop['datetime']= pd.to_datetime(df_synop['datetime'])\n",
    "df_synop=df_synop.rename(columns={\"temp\":\"TEMP_SYNOP\",\"wind_speed\":\"WIND_SPEED_SYNOP\",\"short_wave_from_sky_1hour\":\"RAD_SYNOP\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EY8UJzPr18j3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IUSGQDKeUf_"
   },
   "source": [
    "# Part 2 Feeding the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3VUmHN6i_YhS"
   },
   "outputs": [],
   "source": [
    "df_merged=pd.read_csv('df_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIVNMcI4jJOx"
   },
   "source": [
    "This is how your final data frame should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "i2VngK4DqWy5",
    "outputId": "94d364ff-7cbf-482b-bcfa-7413123853fa"
   },
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnhejWYqtXlE"
   },
   "source": [
    "What does this block of code mean?\n",
    "\n",
    "Why do we have to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G6Cd6uU7rYuv"
   },
   "outputs": [],
   "source": [
    "df_merged=df_merged.dropna()\n",
    "df_merged=df_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGGKsRzJt4VP"
   },
   "source": [
    "We will not need these columns anymore. \n",
    "\n",
    "Why is it important to remove these from the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1FtUj0b7ZIy",
    "outputId": "d2368741-f9da-4e04-dfd1-6ceaeb85f86f"
   },
   "outputs": [],
   "source": [
    "df_merged.pop('Vlinder')\n",
    "df_merged.pop('community_name')\n",
    "df_merged.pop('station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehzYwdLxgNux"
   },
   "source": [
    "Calculate here a correlation matrix for the fetaures. What can we learn from this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJKw9d_wgOff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFR5JR1LgvGU"
   },
   "source": [
    "This particular choice of test set was made in consideration of making the graph at the bottom the of this notebook. Do you perhaps see any problems with this aproach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "djpFnhpj67uP"
   },
   "outputs": [],
   "source": [
    "df_test= df_merged.loc[range(15,60)]\n",
    "df_train= df_merged.loc[range(60,len(df_merged))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfY_GyPXu6vB"
   },
   "source": [
    "Is this block of code optimal. If not, what could be improved here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ms6CTaeJ1kgL",
    "outputId": "def37019-dcd5-452b-d52d-c726d4dd8c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test=df_test.reset_index(drop=True)\n",
    "df_test['DATE']=df_test.TEMP*0\n",
    "df_test['HOUR']=df_test.TEMP*0\n",
    "str_date ='' \n",
    "str_hour=''  \n",
    "for i in range(len(df_test)):\n",
    "  str_tot=df_test.loc[i,'datetime']\n",
    "  str_date=str_tot[8]+str_tot[9]\n",
    "  str_hour=str_tot[11]+str_tot[12]\n",
    "  df_test.loc[i,'DATE']=float(str_date)\n",
    "  df_test.loc[i,'HOUR']=float(str_hour)\n",
    "\n",
    "date=df_test['DATE']\n",
    "hour=df_test['HOUR']\n",
    "df_test.pop('DATE')\n",
    "df_test.pop('HOUR')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um6xctSg3mO3",
    "outputId": "4a19f9f7-1df6-4064-9f9d-43fc050d66b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.pop('datetime')\n",
    "df_test.pop('datetime')\n",
    "df_merged.pop('datetime')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "cn6kHOOnHzvj",
    "outputId": "479b6c4c-1dd6-47a0-8fc0-a889c391518a"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts_F-RjAZwoy"
   },
   "source": [
    "Write here a block of code to scale your data. \n",
    "\n",
    "Look at the sklearn preprocessing library for which scaler (I recommend looking into the MinMaxScaler) you can use and what functionalities there are. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWhVmwR12M77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmag-TNgKMDW"
   },
   "outputs": [],
   "source": [
    "X_train=df_train_scale.drop('TEMP', axis=1)\n",
    "Y_train=df_train_scale['TEMP']\n",
    "X_test=df_test.drop('TEMP', axis=1)\n",
    "Y_test=df_test['TEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01Zhg8T_KA8f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val =train_test_split(X_train,Y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQIaMMWBhIH7"
   },
   "source": [
    "The ML model of choice here is the K-nearest neighbours regression model. This is a non-parametric model where the output for an input vector is calculated by taking an average of the k-nearest neighbours of that input vector in the feature space. For a more thourough explanation on this look at the documentation: https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXIJW-eqPZms"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnbyY44nrX6I"
   },
   "source": [
    "In this part we will evaluate the model for 20 different values of k on the validation set. With this we will determine which value would be optimal. (Hyperparameter tuning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "y8cLsUHcPXZn",
    "outputId": "c42ed2ef-fe2d-49fd-c1c6-176afac0c668"
   },
   "outputs": [],
   "source": [
    "valRMSE=[]\n",
    "for i in range(1,20):\n",
    "    parameter = i\n",
    "    model = KNeighborsRegressor(parameter)\n",
    "    model.fit(X_train,Y_train)\n",
    "    predval = model.predict(X_val)\n",
    "    valerror = Y_val.values-predval.reshape(len(predval))\n",
    "    valRMSE.append(np.sqrt(np.mean(np.square(valerror))))\n",
    "\n",
    "plt.plot(range(1,20), valRMSE,'-*')\n",
    "plt.xlabel(\"number of neighbours k\")\n",
    "plt.ylabel(\"RMSE on the validation set\")\n",
    "plt.title('hyperparameter tuning for KNN')\n",
    "plt.grid()\n",
    "#Choose the best parameter value\n",
    "minindex = np.argmin(valRMSE)\n",
    "print('Chosen parameter: ' + str(minindex+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeoPyA8wxARP"
   },
   "source": [
    "Now that we have chosen the parameter, we train the model using this optimized value for k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOlW3MhwSird"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(minindex+1)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feevtwWN2Yhq"
   },
   "source": [
    "Write in this following block of code you should let your model predict for the test set. *pred_T* should be your answer for the model prediction and *actual_T* should be your actual measurments. Think well about in which format your model will return the prediction and what the inverse scaling function requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om6--s7q3gAe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "GqpukeAkTu1i",
    "outputId": "be1775bb-dcbb-49c5-b0a4-f99c38eff5bb"
   },
   "outputs": [],
   "source": [
    "time=date+hour/24.0\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(time,pred_T,'b')\n",
    "plt.plot(time,actual_T,'k')\n",
    "plt.grid()\n",
    "plt.legend(['Prediction','Actual value'],loc=2)\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Temperature (°C)\")\n",
    "plt.title('Model performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u06AMRruq0Kb"
   },
   "source": [
    "Final part:\n",
    "Calculate the mean absolute error (MAE), root mean squared error (RMSE) and bias.\n",
    "\n",
    "\n",
    "Do these values match the figure above? What could we do to improve these values and our prediction in general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFMpyPNe3fNA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
