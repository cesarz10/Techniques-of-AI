{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4eef7eb2",
      "metadata": {
        "id": "4eef7eb2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e27db6e9",
      "metadata": {
        "id": "e27db6e9"
      },
      "outputs": [],
      "source": [
        "np.random.seed(138)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "88c47eea",
      "metadata": {
        "id": "88c47eea"
      },
      "outputs": [],
      "source": [
        "## Helper function for visualization\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    '''\n",
        "    Plot the decision boundaries of a model trained on 2 dimensionnal data, as\n",
        "    well as the scatter plot of the data X, using the target values in y for\n",
        "    the colors.\n",
        "    ----------------------\n",
        "    Input\n",
        "            - model : Scikit-learn style estimator, already trained, must have\n",
        "                    a .predict method\n",
        "            - X : Data for scatter plot, must have 2 features.\n",
        "            - y : Target classes for scatter plot colors\n",
        "    '''\n",
        "    # Set min and max values and give it some padding\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\n",
        "    # Predict the function value for the whole grid\n",
        "    X_grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "    Z = model.predict(X_grid)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    # Plot the contour and training examples\n",
        "    plt.contourf(xx1, xx2, Z, cmap=plt.cm.Spectral)\n",
        "    plt.ylabel('x2')\n",
        "    plt.xlabel('x1')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.Spectral)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456a47d7",
      "metadata": {
        "id": "456a47d7"
      },
      "source": [
        "# Classification example\n",
        "\n",
        "We will do first a quick example for a classification using the Scikit-learn library. In this example, we generate in a 2D plan three different \"blobs\" of data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ae79eeb3",
      "metadata": {
        "id": "ae79eeb3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72372faf",
      "metadata": {
        "id": "72372faf"
      },
      "outputs": [],
      "source": [
        "# generate 500 samples of data points, with 2 features and 3 different blobs of points\n",
        "X,y = make_blobs(500, 2, centers=3, random_state=42)\n",
        "\n",
        "# Plot the dataset generated\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\")\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e42355",
      "metadata": {
        "id": "10e42355"
      },
      "source": [
        "## Normalizing the data\n",
        "\n",
        "Depending on the optimization technique used for a ML algorithm, you may need to normalize the data to help the model converge during its optimization/fitting/learning process. It is not necessary for all ML algorithm, but if you are going to test a bunch of different ML models, it is better to do it straightaway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c33573dd",
      "metadata": {
        "id": "c33573dd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb6e268",
      "metadata": {
        "id": "8eb6e268"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X = normalizer.fit_transform(X) # find the mean and std for X and then normalize X\n",
        "\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\")\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6a4061",
      "metadata": {
        "id": "8b6a4061"
      },
      "outputs": [],
      "source": [
        "# You can perform the inverse transform later if you want like this\n",
        "X = normalizer.inverse_transform(X)\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\")\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28827a23",
      "metadata": {
        "id": "28827a23"
      },
      "outputs": [],
      "source": [
        "# And transform new data with the previously found values for the mean and std\n",
        "X = normalizer.transform(X)\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\")\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a18911c",
      "metadata": {
        "id": "4a18911c"
      },
      "source": [
        "## Decision Tree\n",
        "\n",
        "To demonstrate the working here we train a decision tree model to show how it classifies the data points and how it creates the boudaries. Run this code a couple of times and observe how the boundaries change."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "dt = tree.DecisionTreeClassifier(max_depth = 3)\n",
        "dt.fit(X, y)\n",
        "y_pred = dt.predict(X)\n",
        "acc = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "plt.figure()\n",
        "plot_decision_boundary(dt, X, y)"
      ],
      "metadata": {
        "id": "r0jyzFTrWBFa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "r0jyzFTrWBFa"
    },
    {
      "cell_type": "markdown",
      "id": "50b4c609",
      "metadata": {
        "id": "50b4c609"
      },
      "source": [
        "# Neural networks\n",
        "\n",
        "The previous example was a simple problem where each class could be linearly separated. We will now look at a different problem where it is not possible anymore to linearly separate each class. The next dataset consist of 500 data points set in a 2d plan and belonging into 2 different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1ab3fc",
      "metadata": {
        "id": "5c1ab3fc"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23021c26",
      "metadata": {
        "id": "23021c26"
      },
      "outputs": [],
      "source": [
        "X,y = make_moons(500, noise=0.1, random_state=42)\n",
        "\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d3e3d2",
      "metadata": {
        "id": "a0d3e3d2"
      },
      "source": [
        "For training a neural network, it is important to normalize the data. If the data is not normalized, the training process can have difficulty to converge to a good solution when using gradient descent to optimize the model paramaters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c275be5c",
      "metadata": {
        "id": "c275be5c"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X = normalizer.fit_transform(X)\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1da253c",
      "metadata": {
        "id": "e1da253c"
      },
      "source": [
        "Let's train a first neural network. We will use the MLPClassifier neural network from Scikit-learn. This model is a multi-layer perceptron where each perceptron/neuron from a specific layer is connected to all neurons of the next layer.\n",
        "\n",
        "To modify the neural network architecture, we can modify the parameter \"hidden_layer_sizes\":\n",
        "\n",
        "- hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
        "    The ith element represents the number of neurons in the ith\n",
        "    hidden layer.\n",
        "    \n",
        "We can also choose the activation function applied to the neurons inside the hidden layers:\n",
        "- activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
        "    Activation function for the hidden layer.\n",
        "\n",
        "    - 'identity', no-op activation, useful to implement linear bottleneck,\n",
        "      returns f(x) = x\n",
        "\n",
        "    - 'logistic', the logistic sigmoid function,\n",
        "      returns f(x) = 1 / (1 + exp(-x)).\n",
        "\n",
        "    - 'tanh', the hyperbolic tan function,\n",
        "      returns f(x) = tanh(x).\n",
        "\n",
        "    - 'relu', the rectified linear unit function,\n",
        "      returns f(x) = max(0, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd041430",
      "metadata": {
        "id": "dd041430"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68f7731",
      "metadata": {
        "id": "b68f7731"
      },
      "source": [
        "First, we use the architecture of the model from question 1. Only 2 neurons in one hidden layer, using the identity activation function (the neurons perform a linear transformation of their inputs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e07ae1",
      "metadata": {
        "id": "38e07ae1"
      },
      "outputs": [],
      "source": [
        "net = MLPClassifier(hidden_layer_sizes=(2), activation=\"identity\")\n",
        "net.fit(X, y)\n",
        "\n",
        "y_pred = net.predict(X)\n",
        "acc = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "plt.figure()\n",
        "plot_decision_boundary(net, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4c834e",
      "metadata": {
        "id": "ef4c834e"
      },
      "source": [
        "The separation of the two classes is linear as we can see. Next, we use a more complex architecture and the hyperbolic tangent activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb8b63c",
      "metadata": {
        "id": "9fb8b63c"
      },
      "outputs": [],
      "source": [
        "net = MLPClassifier(hidden_layer_sizes=(100, 100), activation=\"tanh\")\n",
        "net.fit(X, y)\n",
        "\n",
        "y_pred = net.predict(X)\n",
        "acc = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "plt.figure()\n",
        "plot_decision_boundary(net, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef7b180f",
      "metadata": {
        "id": "ef7b180f"
      },
      "source": [
        "# 1) Experiment with different architectures and activation functions\n",
        "\n",
        "Try by yourself different number of hidden layers and neurons in each layer. Vary also the type of activation function used. Try to estimate if you are underfitting or overfitting in each case.\n",
        "\n",
        "If you have any warning messages appearing, try to understand their reason and how to solve the issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cabcaf",
      "metadata": {
        "id": "24cabcaf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bb16024f",
      "metadata": {
        "id": "bb16024f"
      },
      "source": [
        "# 2) Using a validation dataset to optimize the architecture\n",
        "\n",
        "Separate your dataset into a training, a validation and a test set, then use the validation set to optimize the architecture. Try to pay attention to the computational cost of your models as well.\n",
        "\n",
        "Then use the test set to evaluate the final architecture you have selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "853f0292",
      "metadata": {
        "id": "853f0292"
      },
      "outputs": [],
      "source": [
        "X,y = make_moons(1500, noise=0.3, random_state=42)\n",
        "\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"ro\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d8511c",
      "metadata": {
        "id": "f0d8511c"
      },
      "source": [
        "### Separate the dataset into a training, a validation and a test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6845e56",
      "metadata": {
        "id": "b6845e56"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c808bf30",
      "metadata": {
        "scrolled": true,
        "id": "c808bf30"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1000, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=500, random_state=42)\n",
        "\n",
        "print('# training samples:', len(X_train))\n",
        "print('# validation samples:', len(X_val))\n",
        "print('# test samples:', len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0beb4152",
      "metadata": {
        "id": "0beb4152"
      },
      "source": [
        "### Normalize the data using the statistics of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5b9bc9",
      "metadata": {
        "id": "4c5b9bc9"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train = normalizer.fit_transform(X_train)\n",
        "X_val = normalizer.transform(X_val)\n",
        "X_test = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ac010f",
      "metadata": {
        "id": "a7ac010f"
      },
      "source": [
        "### Architecture search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out a couple of architectures to see which one performes the best"
      ],
      "metadata": {
        "id": "WQF7nQ7lvhR1"
      },
      "id": "WQF7nQ7lvhR1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soop1G5OZsWG"
      },
      "id": "soop1G5OZsWG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUBDJxtMdSvS"
      },
      "id": "TUBDJxtMdSvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JtFpehDdSpN"
      },
      "id": "6JtFpehDdSpN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6canHEDOdSjY"
      },
      "id": "6canHEDOdSjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we use the validation set here instead of the test set?"
      ],
      "metadata": {
        "id": "eBo90iZqvqd9"
      },
      "id": "eBo90iZqvqd9"
    },
    {
      "cell_type": "markdown",
      "id": "c617de9f",
      "metadata": {
        "id": "c617de9f"
      },
      "source": [
        "### Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMS_9u61dSCq"
      },
      "id": "QMS_9u61dSCq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write some code here to asses the accuracy of your best model from the previous section. Plot the boundaries, how do they look like?"
      ],
      "metadata": {
        "id": "lXdNY3OPwUAq"
      },
      "id": "lXdNY3OPwUAq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aditional info: Tensorflow"
      ],
      "metadata": {
        "id": "nUd67b2a0cqj"
      },
      "id": "nUd67b2a0cqj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For neural networks there are also other packages such as Pytorch or tensorflow that allow you to go more indepth with the type of architectures you want to use.\n",
        "we are going to give some example code here that can be toyed with."
      ],
      "metadata": {
        "id": "MfEUHEpH0hpx"
      },
      "id": "MfEUHEpH0hpx"
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXfaq7biwkhu",
        "outputId": "0fd41545-b60d-4f81-a56c-6ba7ec84156a"
      },
      "id": "mXfaq7biwkhu",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "X, y = datasets.load_iris(return_X_y=True, as_frame=True)"
      ],
      "metadata": {
        "id": "BJ3mOg2v03NJ"
      },
      "id": "BJ3mOg2v03NJ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "YzzvOYMo0Zsj"
      },
      "id": "YzzvOYMo0Zsj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "4ir9_fU71KS2"
      },
      "id": "4ir9_fU71KS2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "y_enc = LabelEncoder().fit_transform(y)\n",
        "# Converting the label into a matrix form\n",
        "y_label = tf.keras.utils.to_categorical(y_enc)"
      ],
      "metadata": {
        "id": "l1Nr6Ett_EI0"
      },
      "id": "l1Nr6Ett_EI0",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_label"
      ],
      "metadata": {
        "id": "xNqBGzM3_MZc"
      },
      "id": "xNqBGzM3_MZc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_label, test_size=50, random_state=138)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=25, random_state=138)"
      ],
      "metadata": {
        "id": "ynVCluC31OQr"
      },
      "id": "ynVCluC31OQr",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "normalizer = StandardScaler()\n",
        "X_train = normalizer.fit_transform(X_train)\n",
        "X_val = normalizer.transform(X_val)\n",
        "X_test = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "H9pokEn0Sw93"
      },
      "id": "H9pokEn0Sw93",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can note that there are a lot of hyperparameters and settings here, what do they do?\n",
        "\n",
        "attempt to vary the amount of layers, and the amount of nodes per layer to change the performance of the model."
      ],
      "metadata": {
        "id": "EDodb0lJ3_e0"
      },
      "id": "EDodb0lJ3_e0"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "NNmodel = keras.Sequential([keras.layers.Dense(100, input_dim=X_train.shape[1], activation='relu'),\n",
        "                          keras.layers.Dropout(0.2), #what does this do\n",
        "                          keras.layers.Dense(50, activation='relu'),\n",
        "                          keras.layers.Dense(3, activation='softmax')],  )\n",
        "\n",
        "\n",
        "NNmodel.compile(optimizer='adam',\n",
        "                loss=keras.losses.CategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "history = NNmodel.fit(X_train,y_train, epochs=50, batch_size=10, validation_data=(X_val,y_val), verbose=2)"
      ],
      "metadata": {
        "id": "oHm_ZVhoxp2d"
      },
      "id": "oHm_ZVhoxp2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(10,6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UlFUechwAUEq"
      },
      "id": "UlFUechwAUEq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = NNmodel.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "A1H8qAJo2_TK"
      },
      "id": "A1H8qAJo2_TK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When testing out this model, you will find that the performance of the model is different on every itteration, what is going on here?\n",
        "\n",
        "Tensorflow can also be used for convolutional NN and other fun models such as LSTM."
      ],
      "metadata": {
        "id": "_au8BblV8pDa"
      },
      "id": "_au8BblV8pDa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:sklearn]",
      "language": "python",
      "name": "conda-env-sklearn-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}